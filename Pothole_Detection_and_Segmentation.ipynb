{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byKOC_uof1HG"
      },
      "source": [
        "# **Road Pothole Detection and Segementation with Road Damage Assesement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kqB7hDOgFlM"
      },
      "source": [
        "**Connection to the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl8eqHLjq1j-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tgQ_bH6sMX8"
      },
      "outputs": [],
      "source": [
        "!ls /content/drive/MyDrive/Machine_Vision/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4C5BncGsMaK"
      },
      "outputs": [],
      "source": [
        "!ls /content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gA8o3pfEsMdk"
      },
      "outputs": [],
      "source": [
        "# Installing the Ultralytics: Essential for running YOLOv8 segmentation tailored for pothole detection\n",
        "!pip install ultralytics --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7AtGxIvhtWl"
      },
      "source": [
        "**Importing Necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt1wQs6StcYj"
      },
      "outputs": [],
      "source": [
        "# Importing essential libraries for YOLOv8 pothole segmentation project\n",
        "# Core Python Libraries\n",
        "import random\n",
        "import os     # Handles operating system-related tasks such as file and directory operations.\n",
        "import shutil # Used for high-level file operations like copying, moving, or deleting files and directories\n",
        "import warnings     #  Suppress any unnecessary warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import locale # Handles locale settings (such as language, number formatting, and currency). Used here to ensure correct string formatting.\n",
        "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
        "\n",
        "os.environ['LC_ALL'] = 'en_US.UTF-8'\n",
        "os.environ['LANG'] = 'en_US.UTF-8'\n",
        "\n",
        "# Computer Vision and Image Processing\n",
        "import cv2  # Used for reading, writing, processing, and manipulating images\n",
        "import numpy as np\n",
        "from PIL import Image # A Python Imaging Library alternative for opening, editing, and saving images.\n",
        "\n",
        "from ultralytics import YOLO  #YOLO framework. Allows to load and train YOLO models\n",
        "from collections import deque # A double-ended queue data structure from Pythonâ€™s standard library, useful for efficiently managing a sliding window of detections or predictions\n",
        "\n",
        "# File and Path Handling\n",
        "import yaml   # Used for reading and writing configuration files\n",
        "import pandas as pd\n",
        "from pathlib import Path  # A way to handle file paths, making it easier to work with directories\n",
        "import glob   # A library for finding file paths using pattern matching (e.g., finding all .jpg or .png files in a directory)\n",
        "\n",
        "# Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Video Processing and Display\n",
        "from IPython.display import Video   # Enables displaying videos within Jupyter Notebooks\n",
        "\n",
        "# Customize Seaborn plot vizualization\n",
        "sns.set(rc={'axes.facecolor': '#e0f7fa'}, style='darkgrid')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTaBBSESmNgp"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Dmrey2ytclx"
      },
      "outputs": [],
      "source": [
        "# Model Loading....\n",
        "# YOLOv8n-seg model: Pre-trained for precise segmentation\n",
        "model = YOLO('yolov8n-seg.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP8YBUGK1mD4"
      },
      "source": [
        "**YAML file Info**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFIPXFg1tcn5"
      },
      "outputs": [],
      "source": [
        "# Define the dataset directory and construct the YAML file path using pathlib\n",
        "dataset_dir = Path('/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset')\n",
        "config_file_initial = dataset_dir / 'data.yaml'\n",
        "\n",
        "# Load and display the YAML configuration in a human-readable format\n",
        "with open(config_file_initial, 'r') as stream:\n",
        "    config_data = yaml.safe_load(stream)\n",
        "    print(yaml.dump(config_data, default_flow_style=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9crG5rTtooU6"
      },
      "source": [
        "# **Dataset Information, Preprocessing and Visualizations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8amhsTmjtcrh"
      },
      "outputs": [],
      "source": [
        "# Define directories for training, validation, and test images from the dataset folder\n",
        "train_dir = os.path.join(dataset_dir, 'train', 'images')\n",
        "val_dir = os.path.join(dataset_dir, 'valid', 'images')\n",
        "test_dir = os.path.join(dataset_dir, 'test', 'images')\n",
        "\n",
        "# Initialize counters and sets for storing unique image dimensions\n",
        "train_count, valid_count, test_count = 0, 0, 0\n",
        "train_dims, valid_dims, test_dims = set(), set(), set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8LRXMfSy54b"
      },
      "outputs": [],
      "source": [
        "# Process training images\n",
        "for file in os.listdir(train_dir):\n",
        "    if file.lower().endswith('.jpg'):\n",
        "        train_count += 1\n",
        "        with Image.open(os.path.join(train_dir, file)) as img:\n",
        "            train_dims.add(img.size)\n",
        "\n",
        "# Process validation images\n",
        "for file in os.listdir(val_dir):\n",
        "    if file.lower().endswith('.jpg'):\n",
        "        valid_count += 1\n",
        "        with Image.open(os.path.join(val_dir, file)) as img:\n",
        "            valid_dims.add(img.size)\n",
        "\n",
        "# Process test images\n",
        "for file in os.listdir(test_dir):\n",
        "    if file.lower().endswith('.jpg'):\n",
        "        test_count += 1\n",
        "        with Image.open(os.path.join(test_dir, file)) as img:\n",
        "            test_dims.add(img.size)\n",
        "\n",
        "# Display the total counts for each set\n",
        "print(\"Total training images:\", train_count)\n",
        "print(\"Total validation images:\", valid_count)\n",
        "print(\"Total test images:\", test_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqaEb08vy567"
      },
      "outputs": [],
      "source": [
        "# Check whether all training images share the same dimensions\n",
        "if len(train_dims) == 1:\n",
        "    print(\"Every training image is of size:\", train_dims.pop())\n",
        "else:\n",
        "    print(\"Training images have various sizes:\", train_dims)\n",
        "\n",
        "# Check the validation images for uniformity in dimensions\n",
        "if len(valid_dims) == 1:\n",
        "    print(\"Every validation image is of size:\", valid_dims.pop())\n",
        "else:\n",
        "    print(\"Validation images have different sizes:\", valid_dims)\n",
        "\n",
        "# Check the test images for uniformity in dimensions\n",
        "if len(test_dims) == 1:\n",
        "    print(\"Every test image is of size:\", test_dims.pop())\n",
        "else:\n",
        "    print(\"Test images have different sizes:\", test_dims)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSPTWm19x-L_"
      },
      "source": [
        "### Deleting \"Object\" class to have only the \"Pothole Class\" in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnhEo1lQoJAO"
      },
      "outputs": [],
      "source": [
        "# Define dataset splits and corresponding directories\n",
        "splits = ['train', 'valid', 'test']\n",
        "\n",
        "# Loop through each split (train, valid, test)\n",
        "for split in splits:\n",
        "    labels_dir = os.path.join(dataset_dir, split, 'labels')\n",
        "    images_dir = os.path.join(dataset_dir, split, 'images')\n",
        "\n",
        "    # Check if labels directory exists\n",
        "    if not os.path.exists(labels_dir):\n",
        "        print(f\"Labels directory not found for {split} split: {labels_dir}\")\n",
        "        continue\n",
        "\n",
        "    # Loop through each label file in the directory\n",
        "    for txt_file in os.listdir(labels_dir):\n",
        "        if not txt_file.endswith('.txt'):\n",
        "            continue\n",
        "\n",
        "        txt_path = os.path.join(labels_dir, txt_file)\n",
        "        with open(txt_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        # Flag to determine if \"object\" class (class index 1) is present\n",
        "        remove_file = False\n",
        "        for line in lines:\n",
        "            tokens = line.strip().split()\n",
        "            if tokens and tokens[0] == \"1\":  # \"1\" corresponds to the \"object\" class\n",
        "                remove_file = True\n",
        "                break\n",
        "\n",
        "        if remove_file:\n",
        "            # Delete the label file\n",
        "            print(f\"Deleting label file: {txt_path}\")\n",
        "            os.remove(txt_path)\n",
        "\n",
        "            # Assume the corresponding image has the same base name and a .jpg extension\n",
        "            base_name = os.path.splitext(txt_file)[0]\n",
        "            image_path = os.path.join(images_dir, base_name + '.jpg')\n",
        "            if os.path.exists(image_path):\n",
        "                print(f\"Deleting image file: {image_path}\")\n",
        "                os.remove(image_path)\n",
        "            else:\n",
        "                print(f\"Image file not found for {txt_file} in {images_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFSUYgHQGg3S"
      },
      "outputs": [],
      "source": [
        "def count_images_in_dir(directory, extension='.jpg'):\n",
        "    count = 0\n",
        "    for file in os.listdir(directory):\n",
        "        if file.lower().endswith(extension):\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "# Define directories for images in each split\n",
        "train_dir = os.path.join(dataset_dir, 'train', 'images')\n",
        "val_dir = os.path.join(dataset_dir, 'valid', 'images')\n",
        "test_dir = os.path.join(dataset_dir, 'test', 'images')\n",
        "\n",
        "# Re-count the images after deletion\n",
        "train_count_after = count_images_in_dir(train_dir)\n",
        "val_count_after = count_images_in_dir(val_dir)\n",
        "test_count_after = count_images_in_dir(test_dir)\n",
        "\n",
        "print(\"After deletion:\")\n",
        "print(\"Total training images:\", train_count_after)\n",
        "print(\"Total validation images:\", val_count_after)\n",
        "print(\"Total test images:\", test_count_after)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w-rjnLayXqH"
      },
      "source": [
        "### Removing images and annotation files that have mismatches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJAUHfR1odFq"
      },
      "outputs": [],
      "source": [
        "# Define the labels directory (adjust this path as needed)\n",
        "labels_dir = os.path.join(dataset_dir, 'train', 'labels')\n",
        "\n",
        "# List to keep track of files with annotation issues\n",
        "mismatch_files = []\n",
        "\n",
        "# Iterate over each label file in the directory\n",
        "for filename in os.listdir(labels_dir):\n",
        "    if filename.endswith('.txt'):\n",
        "        filepath = os.path.join(labels_dir, filename)\n",
        "        with open(filepath, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            for idx, line in enumerate(lines):\n",
        "                parts = line.strip().split()\n",
        "                # Check that there's at least one class ID and 6 coordinates (minimum for a triangle polygon)\n",
        "                if len(parts) < 7:\n",
        "                    print(f\"Annotation mismatch in file '{filename}' on line {idx+1}: Not enough elements for a valid segmentation polygon.\")\n",
        "                    mismatch_files.append(filename)\n",
        "                    break  # Stop checking further lines in this file\n",
        "                # Check that the number of coordinates (excluding the class ID) is even\n",
        "                if (len(parts) - 1) % 2 != 0:\n",
        "                    print(f\"Annotation mismatch in file '{filename}' on line {idx+1}: The number of coordinates is not even.\")\n",
        "                    mismatch_files.append(filename)\n",
        "                    break\n",
        "\n",
        "if not mismatch_files:\n",
        "    print(\"No annotation mismatches found.\")\n",
        "else:\n",
        "    print(\"Files with annotation mismatches:\", set(mismatch_files))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxbBYWd9oeV8"
      },
      "outputs": [],
      "source": [
        "# Define the labels directory (adjust this path as needed)\n",
        "labels_dir = os.path.join(dataset_dir, 'test', 'labels')\n",
        "\n",
        "# List to keep track of files with annotation issues\n",
        "mismatch_files = []\n",
        "\n",
        "# Iterate over each label file in the directory\n",
        "for filename in os.listdir(labels_dir):\n",
        "    if filename.endswith('.txt'):\n",
        "        filepath = os.path.join(labels_dir, filename)\n",
        "        with open(filepath, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            for idx, line in enumerate(lines):\n",
        "                parts = line.strip().split()\n",
        "                # Check that there's at least one class ID and 6 coordinates (minimum for a triangle polygon)\n",
        "                if len(parts) < 7:\n",
        "                    print(f\"Annotation mismatch in file '{filename}' on line {idx+1}: Not enough elements for a valid segmentation polygon.\")\n",
        "                    mismatch_files.append(filename)\n",
        "                    break  # Stop checking further lines in this file\n",
        "                # Check that the number of coordinates (excluding the class ID) is even\n",
        "                if (len(parts) - 1) % 2 != 0:\n",
        "                    print(f\"Annotation mismatch in file '{filename}' on line {idx+1}: The number of coordinates is not even.\")\n",
        "                    mismatch_files.append(filename)\n",
        "                    break\n",
        "\n",
        "if not mismatch_files:\n",
        "    print(\"No annotation mismatches found.\")\n",
        "else:\n",
        "    print(\"Files with annotation mismatches:\", set(mismatch_files))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOmROCVcog1u"
      },
      "outputs": [],
      "source": [
        "# Define the labels directory (adjust this path as needed)\n",
        "labels_dir = os.path.join(dataset_dir, 'valid', 'labels')\n",
        "\n",
        "# List to keep track of files with annotation issues\n",
        "mismatch_files = []\n",
        "\n",
        "# Iterate over each label file in the directory\n",
        "for filename in os.listdir(labels_dir):\n",
        "    if filename.endswith('.txt'):\n",
        "        filepath = os.path.join(labels_dir, filename)\n",
        "        with open(filepath, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            for idx, line in enumerate(lines):\n",
        "                parts = line.strip().split()\n",
        "                # Check that there's at least one class ID and 6 coordinates (minimum for a triangle polygon)\n",
        "                if len(parts) < 7:\n",
        "                    print(f\"Annotation mismatch in file '{filename}' on line {idx+1}: Not enough elements for a valid segmentation polygon.\")\n",
        "                    mismatch_files.append(filename)\n",
        "                    break  # Stop checking further lines in this file\n",
        "                # Check that the number of coordinates (excluding the class ID) is even\n",
        "                if (len(parts) - 1) % 2 != 0:\n",
        "                    print(f\"Annotation mismatch in file '{filename}' on line {idx+1}: The number of coordinates is not even.\")\n",
        "                    mismatch_files.append(filename)\n",
        "                    break\n",
        "\n",
        "if not mismatch_files:\n",
        "    print(\"No annotation mismatches found.\")\n",
        "else:\n",
        "    print(\"Files with annotation mismatches:\", set(mismatch_files))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaeer74VD6aa"
      },
      "outputs": [],
      "source": [
        "# Define your dataset directories\n",
        "dataset_dir = '/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset'\n",
        "labels_dir = os.path.join(dataset_dir, 'train', 'labels')\n",
        "images_dir = os.path.join(dataset_dir, 'train', 'images')\n",
        "\n",
        "# Set of label filenames (mismatched annotations) to remove\n",
        "mismatched_files = {\n",
        "    'images84_jpg.rf.8ff54df740279ec03e068c581535e3da.txt', 'images84_jpg.rf.f55527784995caff51379f9308787797.txt'\n",
        "}\n",
        "\n",
        "for txt_filename in mismatched_files:\n",
        "    # Construct full path for the label file\n",
        "    label_file_path = os.path.join(labels_dir, txt_filename)\n",
        "\n",
        "    # Remove the label file if it exists\n",
        "    if os.path.exists(label_file_path):\n",
        "        os.remove(label_file_path)\n",
        "        print(f\"Deleted label file: {label_file_path}\")\n",
        "    else:\n",
        "        print(f\"Label file not found: {label_file_path}\")\n",
        "\n",
        "    # Construct corresponding image filename by replacing .txt with .jpg\n",
        "    image_filename = txt_filename.replace('.txt', '.jpg')\n",
        "    image_file_path = os.path.join(images_dir, image_filename)\n",
        "\n",
        "    # Remove the corresponding image file if it exists\n",
        "    if os.path.exists(image_file_path):\n",
        "        os.remove(image_file_path)\n",
        "        print(f\"Deleted image file: {image_file_path}\")\n",
        "    else:\n",
        "        print(f\"Image file not found: {image_file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM2Zc4STEp_n"
      },
      "outputs": [],
      "source": [
        "# Define your dataset directories\n",
        "dataset_dir = '/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset'\n",
        "labels_dir = os.path.join(dataset_dir, 'test', 'labels')\n",
        "images_dir = os.path.join(dataset_dir, 'test', 'images')\n",
        "\n",
        "# Set of label filenames (mismatched annotations) to remove\n",
        "mismatched_files = {\n",
        "    'images84_jpg.rf.a5560d7daa1adda2732b77141d683a8d.txt'\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "for txt_filename in mismatched_files:\n",
        "    # Construct full path for the label file\n",
        "    label_file_path = os.path.join(labels_dir, txt_filename)\n",
        "\n",
        "    # Remove the label file if it exists\n",
        "    if os.path.exists(label_file_path):\n",
        "        os.remove(label_file_path)\n",
        "        print(f\"Deleted label file: {label_file_path}\")\n",
        "    else:\n",
        "        print(f\"Label file not found: {label_file_path}\")\n",
        "\n",
        "    # Construct corresponding image filename by replacing .txt with .jpg\n",
        "    image_filename = txt_filename.replace('.txt', '.jpg')\n",
        "    image_file_path = os.path.join(images_dir, image_filename)\n",
        "\n",
        "    # Remove the corresponding image file if it exists\n",
        "    if os.path.exists(image_file_path):\n",
        "        os.remove(image_file_path)\n",
        "        print(f\"Deleted image file: {image_file_path}\")\n",
        "    else:\n",
        "        print(f\"Image file not found: {image_file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNqlWimeygDJ"
      },
      "source": [
        "### Final Dataset Image counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYx2boEtIQB-"
      },
      "outputs": [],
      "source": [
        "# Define directories for images in each split\n",
        "train_dir = os.path.join(dataset_dir, 'train', 'images')\n",
        "val_dir = os.path.join(dataset_dir, 'valid', 'images')\n",
        "test_dir = os.path.join(dataset_dir, 'test', 'images')\n",
        "\n",
        "# Re-count the images after deletion\n",
        "train_count_after = count_images_in_dir(train_dir)\n",
        "val_count_after = count_images_in_dir(val_dir)\n",
        "test_count_after = count_images_in_dir(test_dir)\n",
        "\n",
        "print(\"After deletion:\")\n",
        "print(\"Total training images:\", train_count_after)\n",
        "print(\"Total validation images:\", val_count_after)\n",
        "print(\"Total test images:\", test_count_after)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO8eKXw2ykpM"
      },
      "source": [
        "### Updated YAML File for the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyf8EVSIIRL2"
      },
      "outputs": [],
      "source": [
        "# Path to your existing YAML file\n",
        "yaml_file_path = os.path.join(dataset_dir, 'data.yaml')\n",
        "\n",
        "# Load the current YAML file\n",
        "with open(yaml_file_path, 'r') as f:\n",
        "    data = yaml.safe_load(f)\n",
        "\n",
        "# Modify the YAML: remove the \"object\" class and update number of classes to 1\n",
        "data['names'] = ['Pothole']\n",
        "data['nc'] = 1\n",
        "\n",
        "# Save the updated configuration to a new file called new_data.yaml\n",
        "new_yaml_file_path = os.path.join(dataset_dir, 'new_data.yaml')\n",
        "with open(new_yaml_file_path, 'w') as f:\n",
        "    yaml.dump(data, f)\n",
        "\n",
        "print(f\"Updated YAML saved as {new_yaml_file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wW5FPY9-ItK1"
      },
      "outputs": [],
      "source": [
        "# Define the dataset directory and construct the YAML file path using pathlib\n",
        "dataset_dir = Path('/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset')\n",
        "config_file = dataset_dir / 'new_data.yaml'\n",
        "\n",
        "# Load and display the YAML configuration in a human-readable format\n",
        "with open(config_file, 'r') as stream:\n",
        "    config_data = yaml.safe_load(stream)\n",
        "    print(yaml.dump(config_data, default_flow_style=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlqNakUly596"
      },
      "outputs": [],
      "source": [
        "# Randomly select and display 12 training images in a 3x4 grid layout\n",
        "# Create a list of JPEG files from the training directory\n",
        "train_files = [f for f in os.listdir(train_dir) if f.lower().endswith('.jpg')]\n",
        "random.seed(0)\n",
        "sample_files = random.sample(train_files, 12)\n",
        "\n",
        "plt.figure(figsize=(20, 18))\n",
        "for idx, file in enumerate(sample_files):\n",
        "    img = Image.open(os.path.join(train_dir, file))\n",
        "    plt.subplot(3, 4, idx + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle('Randomly Selected Training Images', fontsize=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "del train_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMAqS4q0o5_S"
      },
      "outputs": [],
      "source": [
        "# Define the path to the training labels directory\n",
        "labels_path = os.path.join(dataset_dir, 'train', 'labels')\n",
        "pothole_counts = []\n",
        "total_potholes = 0  # Initialize a counter for total potholes\n",
        "\n",
        "# Iterate through label files and count pothole instances per image\n",
        "for label_file in os.listdir(labels_path):\n",
        "    if label_file.endswith('.txt'):\n",
        "        with open(os.path.join(labels_path, label_file), 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            pothole_counts.append(len(lines))\n",
        "            total_potholes += len(lines)  # Accumulate the count\n",
        "\n",
        "# Print the total number of potholes in the dataset\n",
        "print(f\"Total number of potholes in the training dataset: {total_potholes}\")\n",
        "\n",
        "# Plot a histogram showing the distribution of pothole counts per image\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(pothole_counts, bins=range(0, max(pothole_counts) + 2), align='left', color='skyblue', edgecolor='black')\n",
        "plt.title('Distribution of Pothole Instances per Image')\n",
        "plt.xlabel('Number of Potholes')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9ZhYWZpsgZc"
      },
      "outputs": [],
      "source": [
        "# Example image and label file paths\n",
        "image_path = os.path.join(dataset_dir, 'train', 'images', 'pic-40-_jpg.rf.5dad084d8bfbd13fae7fe0c6b5083048.jpg')\n",
        "label_path = os.path.join(dataset_dir, 'train', 'labels', 'pic-40-_jpg.rf.5dad084d8bfbd13fae7fe0c6b5083048.txt')\n",
        "\n",
        "# Read the image and convert from BGR to RGB for displaying purposes\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "height, width, _ = image.shape\n",
        "\n",
        "# Open and parse the label file to extract the polygon coordinates for one pothole\n",
        "with open(label_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Process the first annotation (one pothole) for demonstration\n",
        "line = lines[0].strip()\n",
        "parts = line.split()\n",
        "# The first element is the class id (0 for potholes), the rest are normalized polygon coordinates\n",
        "polygon_coords = list(map(float, parts[1:]))\n",
        "\n",
        "# Convert normalized coordinates to actual pixel positions\n",
        "points = []\n",
        "for i in range(0, len(polygon_coords), 2):\n",
        "    x_norm, y_norm = polygon_coords[i], polygon_coords[i + 1]\n",
        "    x = int(x_norm * width)\n",
        "    y = int(y_norm * height)\n",
        "    points.append([x, y])\n",
        "points = np.array(points, dtype=np.int32)\n",
        "\n",
        "# Create a mask for the pothole region using the polygon points\n",
        "mask = np.zeros((height, width), dtype=np.uint8)\n",
        "cv2.fillPoly(mask, [points], 255)\n",
        "\n",
        "# Extract the pothole region from the image using the mask\n",
        "pothole_region = cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "# Convert the pothole region to grayscale and apply Canny edge detection\n",
        "pothole_gray = cv2.cvtColor(pothole_region, cv2.COLOR_BGR2GRAY)\n",
        "edges = cv2.Canny(pothole_gray, threshold1=50, threshold2=150)\n",
        "\n",
        "# Plot the original image, the pothole region, and the detected edges\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(image_rgb)\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "# Convert BGR to RGB for displaying the pothole region\n",
        "plt.imshow(cv2.cvtColor(pothole_region, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Pothole Region')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(edges, cmap='gray')\n",
        "plt.title('Edge Detection (Canny)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pW7ePd4v0udR"
      },
      "outputs": [],
      "source": [
        "# Print a summary of the YOLOv8 model architecture\n",
        "model.info()  # Displays model info and architecture details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bfsv8ida032F"
      },
      "outputs": [],
      "source": [
        "print(model.model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKEaBG8DuMz9"
      },
      "source": [
        "# **Model Traning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oVUxE7Hy5_6"
      },
      "outputs": [],
      "source": [
        "# Training the YOLOv8n model using selected Hyperparameters\n",
        "model_results = model.train(\n",
        "    data=config_file,     # Path to the dataset configuration\n",
        "    epochs=150,             # Number of training epochs\n",
        "    imgsz=640,            # Input image size (square)\n",
        "    patience=15,          # Early stopping patience based on validation loss\n",
        "    batch=16,             # Number of images per batch\n",
        "    optimizer='AdamW',    # Selected Optimizer\n",
        "    lr0=0.0001,            # Selected initial learning rate\n",
        "    lrf=0.01,             # Final learning rate multiplier (lr0 * lrf)\n",
        "    momentum=0.9,         # Chosen momentum value\n",
        "    dropout=0.25,          # Dropout rate for regularization\n",
        "    device=0,             # Device to run the training on (e.g., GPU index)\n",
        "    seed=42               # Seed for reproducibility\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPOKUL9v0Rvy"
      },
      "outputs": [],
      "source": [
        "# Directories to check\n",
        "dirs = [\"runs/segment/train\"]\n",
        "\n",
        "for directory in dirs:\n",
        "    print(f\"\\nContents of {directory}:\\n\")\n",
        "    if os.path.exists(directory):\n",
        "        files = os.listdir(directory)\n",
        "        for file in files:\n",
        "            print(file)\n",
        "    else:\n",
        "        print(\"Directory not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZ1x0oeK0Rzf"
      },
      "outputs": [],
      "source": [
        "# Define source and destination paths\n",
        "source_dirs = [\"runs/segment/train\"]\n",
        "destination = \"/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/results\"\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "os.makedirs(destination, exist_ok=True)\n",
        "\n",
        "# Move the directories to Google Drive\n",
        "for src in source_dirs:\n",
        "    if os.path.exists(src):\n",
        "        dst = os.path.join(destination, os.path.basename(src))\n",
        "        shutil.move(src, dst)\n",
        "        print(f\"Moved {src} to {dst}\")\n",
        "    else:\n",
        "        print(f\"Source directory {src} not found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF3P5W20-S6b"
      },
      "source": [
        "# **Model Performance Evaluation - Training & Validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL02aLua-GyG"
      },
      "source": [
        "**Post-training result images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdS1Mg_Y0R10"
      },
      "outputs": [],
      "source": [
        "# Specify the directory containing post-training result images\n",
        "results_dir = '/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/results/train'\n",
        "\n",
        "# Construct the complete path for the results image file\n",
        "results_img_path = os.path.join(results_dir, 'results.png')\n",
        "\n",
        "# Function to display the training/validation results image\n",
        "def show_results(image_path):\n",
        "    # Load the image in BGR format and convert to RGB for accurate color rendering\n",
        "    image_bgr = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Create a figure with a custom background color and size\n",
        "    fig, ax = plt.subplots(figsize=(20, 8), facecolor='#f9f9f9')\n",
        "    ax.imshow(image_rgb)\n",
        "\n",
        "    ax.set_title('Loss Trends: Training and Validation', fontsize=20, color='navy')\n",
        "    ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_results(results_img_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CbgnyeH0R5Q"
      },
      "outputs": [],
      "source": [
        "# Construct path and load CSV data\n",
        "results_csv_path = os.path.join(results_dir, 'results.csv')\n",
        "df = pd.read_csv(results_csv_path)\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Plot training and validation bounding box loss\n",
        "plt.figure(figsize=(8, 2))\n",
        "plt.plot(df['epoch'], df['train/box_loss'], label='Train Box Loss', color='teal', linewidth=2)\n",
        "plt.plot(df['epoch'], df['val/box_loss'], label='Val Box Loss', color='coral', linestyle='--', linewidth=2)\n",
        "plt.title('Bounding Box Loss Learning Curve', fontsize=12)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0, 2)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ywn1oUgRy6CB"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation classification loss\n",
        "plt.figure(figsize=(8, 2))\n",
        "plt.plot(df['epoch'], df['train/cls_loss'], label='Train Cls Loss', color='purple', linewidth=2)\n",
        "plt.plot(df['epoch'], df['val/cls_loss'], label='Val Cls Loss', color='orange', linestyle='--', linewidth=2)\n",
        "plt.title('Classification Loss Learning Curve', fontsize=12)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0, 2)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4slD-NRD7fpm"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation DFL loss\n",
        "plt.figure(figsize=(8, 2))\n",
        "plt.plot(df['epoch'], df['train/dfl_loss'], label='Train DFL Loss', color='darkgreen', linewidth=2)\n",
        "plt.plot(df['epoch'], df['val/dfl_loss'], label='Val DFL Loss', color='red', linestyle='--', linewidth=2)\n",
        "plt.title('Distribution Focal Loss Learning Curve', fontsize=12)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0, 2)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI1iP3yj7loy"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation segmentation loss\n",
        "plt.figure(figsize=(8, 2))\n",
        "plt.plot(df['epoch'], df['train/seg_loss'], label='Train Seg Loss', color='navy', linewidth=2)\n",
        "plt.plot(df['epoch'], df['val/seg_loss'], label='Val Seg Loss', color='magenta', linestyle='--', linewidth=2)\n",
        "plt.title('Segmentation Loss Learning Curve', fontsize=12)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0, 5)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGydbenZy6Fd"
      },
      "outputs": [],
      "source": [
        "# Define a function to load an image and convert its color from BGR to RGB\n",
        "def load_rgb_image(path):\n",
        "    img = cv2.imread(path)\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Create lists of tuples for 'Box' and 'Mask' metrics with filenames and titles\n",
        "box_plots = [\n",
        "    ('BoxP_curve.png', 'Bounding Box Precision-Confidence Curve'),\n",
        "    ('BoxR_curve.png', 'Bounding Box Recall-Confidence Curve'),\n",
        "    ('BoxF1_curve.png', 'Bounding Box F1-Confidence Curve')\n",
        "]\n",
        "\n",
        "mask_plots = [\n",
        "    ('MaskP_curve.png', 'Mask Precision-Confidence Curve'),\n",
        "    ('MaskR_curve.png', 'Mask Recall-Confidence Curve'),\n",
        "    ('MaskF1_curve.png', 'Mask F1-Confidence Curve')\n",
        "]\n",
        "\n",
        "# Set up a new figure with a specified size\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# There are 6 images in total; arrange them in a 3x2 grid using plt.subplot\n",
        "for idx, (filename, title) in enumerate(box_plots):\n",
        "    img_path = os.path.join(results_dir, filename)\n",
        "    img = load_rgb_image(img_path)\n",
        "    plt.subplot(3, 2, 2 * idx + 1)  # Place in the first column of each row\n",
        "    plt.imshow(img)\n",
        "    plt.title(title, fontsize=12,color='darkgreen')\n",
        "    plt.axis('off')\n",
        "\n",
        "for idx, (filename, title) in enumerate(mask_plots):\n",
        "    img_path = os.path.join(results_dir, filename)\n",
        "    img = load_rgb_image(img_path)\n",
        "    plt.subplot(3, 2, 2 * idx + 2)  # Place in the second column of each row\n",
        "    plt.imshow(img)\n",
        "    plt.title(title, fontsize=12, color='darkblue')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g3ioiFMSd-2"
      },
      "outputs": [],
      "source": [
        "def display_metric_curves(metric_dict, folder, grid_dims=(1, 2)):\n",
        "    rows, cols = grid_dims\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Iterate over each metric image\n",
        "    for idx, (img_file, caption) in enumerate(metric_dict.items()):\n",
        "        # Build the full image path\n",
        "        path = os.path.join(folder, img_file)\n",
        "\n",
        "        # Load the image using cv2 and convert its color space from BGR to RGB\n",
        "        loaded_img = cv2.imread(path)\n",
        "        converted_img = cv2.cvtColor(loaded_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Add a subplot for the current image\n",
        "        ax = fig.add_subplot(rows, cols, idx + 1)\n",
        "        ax.imshow(converted_img)\n",
        "        ax.set_title(caption, fontsize=12, color='darkred')\n",
        "        ax.axis('off')\n",
        "\n",
        "    # Adjust the layout and display the figure\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage with 'Box' and 'Mask' Precision-Recall curves:\n",
        "pr_metrics = {\n",
        "    'BoxPR_curve.png': 'Bounding Box Precision-Recall Curve',\n",
        "    'MaskPR_curve.png': 'Mask Precision-Recall Curve'\n",
        "}\n",
        "\n",
        "display_metric_curves(pr_metrics, results_dir, grid_dims=(1, 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unq-ghceSeCO"
      },
      "outputs": [],
      "source": [
        "def show_confusion_images(raw_img_path, norm_img_path, size=(18, 9)):\n",
        "    # Load the raw image and convert its color from BGR to RGB\n",
        "    raw_image = cv2.imread(raw_img_path)\n",
        "    raw_rgb = cv2.cvtColor(raw_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Load the normalized image and convert its color from BGR to RGB\n",
        "    norm_image = cv2.imread(norm_img_path)\n",
        "    norm_rgb = cv2.cvtColor(norm_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Create a figure and add two subplots manually\n",
        "    fig = plt.figure(figsize=size)\n",
        "\n",
        "    ax_raw = fig.add_subplot(1, 2, 1)\n",
        "    ax_raw.imshow(raw_rgb)\n",
        "    ax_raw.set_title('Confusion Matrix Overview', fontsize=12, color='darkred')\n",
        "    ax_raw.axis('off')\n",
        "\n",
        "    ax_norm = fig.add_subplot(1, 2, 2)\n",
        "    ax_norm.imshow(norm_rgb)\n",
        "    ax_norm.set_title('Normalized Confusion Matrix Overview', fontsize=12, color='darkblue')\n",
        "    ax_norm.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Define file paths for the confusion matrix images\n",
        "raw_confusion_path = os.path.join(results_dir, 'confusion_matrix.png')\n",
        "normalized_confusion_path = os.path.join(results_dir, 'confusion_matrix_normalized.png')\n",
        "\n",
        "# Call the function to display the images\n",
        "show_confusion_images(raw_confusion_path, normalized_confusion_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ab4WCiK-nrf"
      },
      "source": [
        "# **Model Evalution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDQR7BeSSeGN"
      },
      "outputs": [],
      "source": [
        "def load_and_evaluate_model(results_folder, weight_file, dataset='test'):\n",
        "    # Construct the full path to the best model weights\n",
        "    weight_path = os.path.join(results_folder, 'weights', weight_file)\n",
        "\n",
        "    # Load the model using the best weights\n",
        "    model_instance = YOLO(weight_path)\n",
        "\n",
        "    # Evaluate the model on the given dataset split\n",
        "    evaluation_results = model_instance.val(split=dataset)\n",
        "    return evaluation_results\n",
        "\n",
        "# Define the directory containing your results and the best weights filename\n",
        "results_directory = results_dir\n",
        "best_weights = 'best.pt'\n",
        "\n",
        "# Load and evaluate the model; store evaluation metrics\n",
        "eval_metrics = load_and_evaluate_model(results_directory, best_weights, dataset='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzW5YbdVTHBi"
      },
      "outputs": [],
      "source": [
        "# Transform the evaluation metrics dictionary into a DataFrame\n",
        "# Using pd.Series to convert the dictionary, then converting it into a DataFrame\n",
        "\n",
        "filtered_results = {k: v for k, v in eval_metrics.results_dict.items() if k.startswith('metrics/')}\n",
        "\n",
        "# Convert the results into a DataFrame\n",
        "metrics_series = pd.Series(filtered_results)\n",
        "metrics_df = metrics_series.to_frame(name='Metric Value')\n",
        "\n",
        "# Round the metric values for a cleaner display and print the table\n",
        "print(metrics_df.round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rTGFkINUA6E"
      },
      "outputs": [],
      "source": [
        "# Directories to check\n",
        "dirs_2 = [\"runs/segment/val\"]\n",
        "\n",
        "for directory in dirs_2:\n",
        "    print(f\"\\nContents of {directory}:\\n\")\n",
        "    if os.path.exists(directory):\n",
        "        files = os.listdir(directory)\n",
        "        for file in files:\n",
        "            print(file)\n",
        "    else:\n",
        "        print(\"Directory not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rtSflYD5UU0B"
      },
      "outputs": [],
      "source": [
        "# Define source and destination paths\n",
        "source_dirs_2 = [\"runs/segment/val\"]\n",
        "destination_2 = \"/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/results\"\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "os.makedirs(destination_2, exist_ok=True)\n",
        "\n",
        "# Move the directories to Google Drive\n",
        "for src in source_dirs_2:\n",
        "    if os.path.exists(src):\n",
        "        dst = os.path.join(destination_2, os.path.basename(src))\n",
        "        shutil.move(src, dst)\n",
        "        print(f\"Moved {src} to {dst}\")\n",
        "    else:\n",
        "        print(f\"Source directory {src} not found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPIa53AM-ttz"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiJ5jBHP4nuv"
      },
      "outputs": [],
      "source": [
        "results_dir2 = '/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/results/val'\n",
        "\n",
        "# Define file paths for the confusion matrix images\n",
        "raw_confusion_path_test = os.path.join(results_dir2, 'confusion_matrix.png')\n",
        "normalized_confusion_path_test = os.path.join(results_dir2, 'confusion_matrix_normalized.png')\n",
        "\n",
        "# Call the function to display the images\n",
        "show_confusion_images(raw_confusion_path_test, normalized_confusion_path_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdvSZHm-6NR0"
      },
      "outputs": [],
      "source": [
        "# Create lists of tuples for 'Box' and 'Mask' metrics with filenames and titles\n",
        "box_plots = [\n",
        "    ('BoxP_curve.png', 'Bounding Box Precision-Confidence Curve'),\n",
        "    ('BoxR_curve.png', 'Bounding Box Recall-Confidence Curve'),\n",
        "    ('BoxF1_curve.png', 'Bounding Box F1-Confidence Curve')\n",
        "]\n",
        "\n",
        "mask_plots = [\n",
        "    ('MaskP_curve.png', 'Mask Precision-Confidence Curve'),\n",
        "    ('MaskR_curve.png', 'Mask Recall-Confidence Curve'),\n",
        "    ('MaskF1_curve.png', 'Mask F1-Confidence Curve')\n",
        "]\n",
        "\n",
        "# Set up a new figure with a specified size\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# There are 6 images in total; arrange them in a 3x2 grid using plt.subplot\n",
        "for idx, (filename, title) in enumerate(box_plots):\n",
        "    img_path = os.path.join(results_dir2, filename)\n",
        "    img = load_rgb_image(img_path)\n",
        "    plt.subplot(3, 2, 2 * idx + 1)  # Place in the first column of each row\n",
        "    plt.imshow(img)\n",
        "    plt.title(title, fontsize=12,color='darkgreen')\n",
        "    plt.axis('off')\n",
        "\n",
        "for idx, (filename, title) in enumerate(mask_plots):\n",
        "    img_path = os.path.join(results_dir, filename)\n",
        "    img = load_rgb_image(img_path)\n",
        "    plt.subplot(3, 2, 2 * idx + 2)  # Place in the second column of each row\n",
        "    plt.imshow(img)\n",
        "    plt.title(title, fontsize=12, color='darkblue')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g22wgvpC63bE"
      },
      "outputs": [],
      "source": [
        "# Example usage with 'Box' and 'Mask' Precision-Recall curves:\n",
        "pr_metrics = {\n",
        "    'BoxPR_curve.png': 'Bounding Box Precision-Recall Curve',\n",
        "    'MaskPR_curve.png': 'Mask Precision-Recall Curve'\n",
        "}\n",
        "\n",
        "display_metric_curves(pr_metrics, results_dir2, grid_dims=(1, 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5ThKTqN-yjX"
      },
      "source": [
        "**Model Inferencing : Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3yaesnZTG7W"
      },
      "outputs": [],
      "source": [
        "# Define the full path to the best model weights file\n",
        "best_model_path = os.path.join(results_directory, 'weights', best_weights)\n",
        "\n",
        "# Create a YOLO model instance using the best weights\n",
        "best_model = YOLO(best_model_path)\n",
        "\n",
        "def display_test_inferences(test_dir, model_instance, num_samples=9, img_size=640):\n",
        "    # Retrieve a sorted list of JPEG images in the test directory\n",
        "    all_images = sorted([f for f in os.listdir(test_dir) if f.lower().endswith('.jpg')])\n",
        "    total_imgs = len(all_images)\n",
        "\n",
        "    # Evenly select image indices (if total_imgs < num_samples, use all images)\n",
        "    if total_imgs >= num_samples:\n",
        "        indices = np.linspace(0, total_imgs - 1, num=num_samples, dtype=int)\n",
        "    else:\n",
        "        indices = np.arange(total_imgs)\n",
        "\n",
        "    selected_imgs = [all_images[i] for i in indices]\n",
        "\n",
        "    # Create a figure with a 3x3 grid for displaying results\n",
        "    fig = plt.figure(figsize=(8, 9))\n",
        "    fig.suptitle('Testing Inference Results', fontsize=24, color='darkgreen')\n",
        "\n",
        "    # Loop through each selected image, run inference, and plot the annotated output\n",
        "    for idx, img_name in enumerate(selected_imgs):\n",
        "        img_full_path = os.path.join(test_dir, img_name)\n",
        "        inference = model_instance.predict(source=img_full_path, imgsz=img_size)\n",
        "        # Get the annotated image (assumed to be in BGR) and convert to RGB for display\n",
        "        annotated_bgr = inference[0].plot()\n",
        "        annotated_rgb = cv2.cvtColor(annotated_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        ax = fig.add_subplot(3, 3, idx + 1)\n",
        "        ax.imshow(annotated_rgb)\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Define the test images directory path\n",
        "testing_dir = os.path.join(dataset_dir, 'test', 'images')\n",
        "\n",
        "# Call the function to display 9 evenly spaced test inferences using the best_model\n",
        "display_test_inferences(testing_dir, best_model, num_samples=9, img_size=640)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1R8-UiD-7c4"
      },
      "source": [
        "**Additional Evaluation Metrics : Average IoU and Dice Score**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kjBtkWukrw9w"
      },
      "outputs": [],
      "source": [
        "# Load Ground Truth Mask\n",
        "\n",
        "def load_ground_truth_mask(img_path, labels_folder):\n",
        "    # Derive label filename from the image filename\n",
        "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    label_path = os.path.join(labels_folder, base_name + '.txt')\n",
        "\n",
        "    # Read the image to get its dimensions\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        print(f\"Warning: Could not read image at {img_path}\")\n",
        "        return None\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Initialize a blank mask\n",
        "    mask = np.zeros((height, width), dtype=np.uint8)\n",
        "\n",
        "    # If the label file doesn't exist, return an all-zero mask (no pothole)\n",
        "    if not os.path.exists(label_path):\n",
        "        return mask\n",
        "\n",
        "    # Parse each line (each polygon) and draw it on the mask\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            # The first part is the class ID, the rest are polygon coords\n",
        "            polygon_coords = list(map(float, parts[1:]))\n",
        "            points = []\n",
        "            for i in range(0, len(polygon_coords), 2):\n",
        "                x_norm, y_norm = polygon_coords[i], polygon_coords[i + 1]\n",
        "                x = int(x_norm * width)\n",
        "                y = int(y_norm * height)\n",
        "                points.append([x, y])\n",
        "            points = np.array(points, dtype=np.int32)\n",
        "            cv2.fillPoly(mask, [points], 255)\n",
        "\n",
        "    return mask\n",
        "\n",
        "# Load Ground Truth Bounding Boxes\n",
        "\n",
        "def load_ground_truth_boxes(img_path, labels_folder):\n",
        "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    label_path = os.path.join(labels_folder, base_name + '.txt')\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        print(f\"Warning: Could not read image at {img_path}\")\n",
        "        return []\n",
        "    height, width, _ = image.shape\n",
        "    gt_boxes = []\n",
        "    if not os.path.exists(label_path):\n",
        "        return gt_boxes\n",
        "\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            # Skip class id (parts[0]) and get polygon coordinates\n",
        "            polygon_coords = list(map(float, parts[1:]))\n",
        "            points = []\n",
        "            for i in range(0, len(polygon_coords), 2):\n",
        "                x_norm = polygon_coords[i]\n",
        "                y_norm = polygon_coords[i+1]\n",
        "                x = int(x_norm * width)\n",
        "                y = int(y_norm * height)\n",
        "                points.append([x, y])\n",
        "            points = np.array(points, dtype=np.int32)\n",
        "            # Compute bounding rectangle from the polygon\n",
        "            x, y, w, h = cv2.boundingRect(points)\n",
        "            gt_boxes.append([x, y, x+w, y+h])\n",
        "    return gt_boxes\n",
        "\n",
        "\n",
        "# Compute IoU and Dice/F1 for a Single Pair of Masks\n",
        "\n",
        "def compute_iou_dice(pred_mask, gt_mask):\n",
        "    # Convert masks to binary\n",
        "    pred_bin = (pred_mask > 0).astype(np.uint8)\n",
        "    gt_bin   = (gt_mask   > 0).astype(np.uint8)\n",
        "\n",
        "    intersection = np.sum(pred_bin * gt_bin)\n",
        "    union = np.sum((pred_bin + gt_bin) > 0)\n",
        "\n",
        "    iou = intersection / union if union != 0 else 0.0\n",
        "\n",
        "    # Dice coefficient (equivalent to F1 in segmentation)\n",
        "    denom = np.sum(pred_bin) + np.sum(gt_bin)\n",
        "    dice = (2.0 * intersection) / denom if denom != 0 else 0.0\n",
        "\n",
        "    return iou, dice\n",
        "\n",
        "\n",
        "# Compute IoU for Two Boxes\n",
        "\n",
        "def compute_box_iou(boxA, boxB):\n",
        "    # Boxes are [x1, y1, x2, y2]\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
        "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
        "    union = boxAArea + boxBArea - interArea\n",
        "    iou = interArea / union if union != 0 else 0.0\n",
        "    return iou\n",
        "\n",
        "# Evaluate Metrics for Boxes and Masks Across the Test Set\n",
        "\n",
        "def evaluate_metrics(model, test_images_dir, test_labels_dir, conf=0.5, imgsz=640):\n",
        "    image_files = glob.glob(os.path.join(test_images_dir, '*.jpg'))\n",
        "\n",
        "    box_iou_list = []\n",
        "    box_f1_list = []\n",
        "    mask_iou_list = []\n",
        "    mask_f1_list = []\n",
        "\n",
        "    for img_path in image_files:\n",
        "        # Load ground truth mask and boxes\n",
        "        gt_mask = load_ground_truth_mask(img_path, test_labels_dir)\n",
        "        if gt_mask is None:\n",
        "            continue\n",
        "        gt_boxes = load_ground_truth_boxes(img_path, test_labels_dir)\n",
        "\n",
        "        # Run model inference to get predicted masks and boxes\n",
        "        results = model.predict(source=img_path, imgsz=imgsz, conf=conf)\n",
        "        result = results[0]\n",
        "\n",
        "        # Evaluate Masks\n",
        "\n",
        "        pred_mask = np.zeros_like(gt_mask)\n",
        "        if result.masks is not None:\n",
        "            mask_data = result.masks.data.cpu().numpy()  # shape: [N, H, W]\n",
        "            for m in mask_data:\n",
        "                pred_mask[m > 0] = 255\n",
        "        m_iou, m_dice = compute_iou_dice(pred_mask, gt_mask)\n",
        "        mask_iou_list.append(m_iou)\n",
        "        mask_f1_list.append(m_dice)  # Dice is equivalent to F1 score for segmentation\n",
        "\n",
        "        # Evaluate Boxes\n",
        "\n",
        "        pred_boxes = []\n",
        "        if hasattr(result, 'boxes') and result.boxes is not None:\n",
        "            # Extract predicted boxes in [x1, y1, x2, y2] format\n",
        "            pred_boxes_array = result.boxes.xyxy.cpu().numpy()  # shape: [N, 4]\n",
        "            for box in pred_boxes_array:\n",
        "                pred_boxes.append(box)\n",
        "\n",
        "        # Greedy matching between predicted boxes and ground truth boxes\n",
        "        matches = []   # store IoU for each matched pair\n",
        "        used_preds = set()\n",
        "        for gt_box in gt_boxes:\n",
        "            best_iou = 0\n",
        "            best_idx = -1\n",
        "            for i, pred_box in enumerate(pred_boxes):\n",
        "                if i in used_preds:\n",
        "                    continue\n",
        "                iou_val = compute_box_iou(gt_box, pred_box)\n",
        "                if iou_val > best_iou:\n",
        "                    best_iou = iou_val\n",
        "                    best_idx = i\n",
        "            if best_iou >= 0.5:  # Consider as a true positive if IoU >= 0.5\n",
        "                matches.append(best_iou)\n",
        "                used_preds.add(best_idx)\n",
        "\n",
        "        # Calculate precision, recall, F1 for boxes\n",
        "        TP = len(matches)\n",
        "        FP = len(pred_boxes) - TP\n",
        "        FN = len(gt_boxes) - TP\n",
        "        box_f1 = (2 * TP) / (2 * TP + FP + FN) if (2 * TP + FP + FN) > 0 else 0.0\n",
        "        box_mean_iou = np.mean(matches) if matches else 0.0\n",
        "\n",
        "        box_iou_list.append(box_mean_iou)\n",
        "        box_f1_list.append(box_f1)\n",
        "\n",
        "    # Compute mean values over all images\n",
        "    mean_box_iou = np.mean(box_iou_list) if box_iou_list else 0.0\n",
        "    mean_box_f1 = np.mean(box_f1_list) if box_f1_list else 0.0\n",
        "    mean_mask_iou = np.mean(mask_iou_list) if mask_iou_list else 0.0\n",
        "    mean_mask_f1 = np.mean(mask_f1_list) if mask_f1_list else 0.0\n",
        "\n",
        "    return mean_box_iou, mean_box_f1, mean_mask_iou, mean_mask_f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCUz4Pud7TuY"
      },
      "outputs": [],
      "source": [
        "test_images_dir = os.path.join(dataset_dir, 'test', 'images')\n",
        "test_labels_dir = os.path.join(dataset_dir, 'test', 'labels')\n",
        "\n",
        "mean_box_iou, mean_box_f1, mean_mask_iou, mean_mask_f1 = evaluate_metrics(best_model, test_images_dir, test_labels_dir)\n",
        "print(f\"Box IoU: {mean_box_iou:.3f}, Box F1: {mean_box_f1:.3f}\")\n",
        "print(f\"Mask IoU: {mean_mask_iou:.3f}, Mask F1: {mean_mask_f1:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ73oIT5_G8N"
      },
      "source": [
        "**Infecencing : Test Video**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2HtNia8GG5g5"
      },
      "outputs": [],
      "source": [
        "# Specify the path to sample video\n",
        "sample_vid = '/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/sample_video.mp4'\n",
        "\n",
        "# Run inference on the sample video using the best model and save the output results\n",
        "best_model.predict(source=sample_vid, save=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnEU7NngWtC9"
      },
      "outputs": [],
      "source": [
        "# Directories to check\n",
        "dirs_3 = [\"runs/segment/predict\"]\n",
        "\n",
        "for directory in dirs_3:\n",
        "    print(f\"\\nContents of {directory}:\\n\")\n",
        "    if os.path.exists(directory):\n",
        "        files = os.listdir(directory)\n",
        "        for file in files:\n",
        "            print(file)\n",
        "    else:\n",
        "        print(\"Directory not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn4sj3McW6U5"
      },
      "outputs": [],
      "source": [
        "# Define source and destination paths\n",
        "source_dirs_3 = [\"runs/segment/predict\"]\n",
        "destination_3 = \"/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/results\"\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "os.makedirs(destination_3, exist_ok=True)\n",
        "\n",
        "# Move the directories to Google Drive\n",
        "for src in source_dirs_3:\n",
        "    if os.path.exists(src):\n",
        "        dst = os.path.join(destination_3, os.path.basename(src))\n",
        "        shutil.move(src, dst)\n",
        "        print(f\"Moved {src} to {dst}\")\n",
        "    else:\n",
        "        print(f\"Source directory {src} not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3tib-lv4VhBC"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "export LC_ALL=en_US.UTF-8\n",
        "export LANG=en_US.UTF-8\n",
        "ffmpeg -i \"/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/results/predict/sample_video.avi\" \\\n",
        "-c:v libx264 -preset fast -crf 22 -c:a aac -strict experimental \\\n",
        "\"/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/results/predict/sample_video.mp4\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5Jafzjgft8_"
      },
      "outputs": [],
      "source": [
        "# Embed the converted video in the notebook for playback\n",
        "DisplayVideo = Video(\"/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/results/predict/sample_video.mp4\",\n",
        "                     embed=True, width=600, height=400)\n",
        "DisplayVideo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsqsEvaS_4CP"
      },
      "outputs": [],
      "source": [
        "# Specify the directory containing whole dataset\n",
        "dataset_dir = Path('/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset')\n",
        "\n",
        "# Specify the directory containing post-training result images\n",
        "results_dir = '/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/results/train'\n",
        "best_weights = 'best.pt'\n",
        "# Define the full path to the best model weights file\n",
        "best_model_path = os.path.join(results_dir, 'weights', best_weights)\n",
        "\n",
        "# Create a YOLO model instance using the best weights\n",
        "best_model = YOLO(best_model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kXm_CwcDW7u7"
      },
      "outputs": [],
      "source": [
        "# Exporting the model\n",
        "best_model.export(format='onnx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ-Vnsb9_TJm"
      },
      "source": [
        "# **Real-Time Pothole Damage Assement**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0haFMV6XTN-"
      },
      "outputs": [],
      "source": [
        "def display_inference_and_masks(testing_dir, sample_idx, yolo_model, img_size=640, conf_thresh=0.5):\n",
        "    # Get the list of JPEG images in the testing folder\n",
        "    test_imgs = [fname for fname in os.listdir(testing_dir) if fname.lower().endswith('.jpg')]\n",
        "\n",
        "    # Select the image at the given index\n",
        "    chosen_img = test_imgs[sample_idx]\n",
        "    full_img_path = os.path.join(testing_dir, chosen_img)\n",
        "\n",
        "    # Run prediction using the YOLO model\n",
        "    pred_results = yolo_model.predict(source=full_img_path, imgsz=img_size, conf=conf_thresh)\n",
        "\n",
        "    # Get the annotated image and convert BGR to RGB for display\n",
        "    annotated = pred_results[0].plot()\n",
        "    annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Count the number of segmentation masks (if any)\n",
        "    mask_plots = len(pred_results[0].masks.data) if pred_results[0].masks is not None else 0\n",
        "    total_plots = 1 + mask_plots\n",
        "\n",
        "    # Create a row of subplots for the annotated image and each mask\n",
        "    fig, axes = plt.subplots(1, total_plots, figsize=(15, 5))\n",
        "    if total_plots == 1:  # Ensure axes is iterable when there's only one plot\n",
        "        axes = [axes]\n",
        "\n",
        "    # Display the main annotated image\n",
        "    axes[0].imshow(annotated_rgb)\n",
        "    axes[0].set_title('Annotated Output')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Display each segmentation mask if available\n",
        "    if pred_results[0].masks is not None:\n",
        "        mask_array = pred_results[0].masks.data.cpu().numpy()\n",
        "        for idx, mask in enumerate(mask_array):\n",
        "            binary_mask = (mask > 0).astype(np.uint8) * 255\n",
        "            axes[idx + 1].imshow(binary_mask, cmap='gray')\n",
        "            axes[idx + 1].set_title(f'Segmentation Mask {idx + 1}')\n",
        "            axes[idx + 1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return pred_results\n",
        "\n",
        "# Helper function to classify overall road damage severity based on overall damage percentage\n",
        "def classify_severity(damage_percentage):\n",
        "    if damage_percentage < 5:\n",
        "        return \"Minor\"\n",
        "    elif damage_percentage < 15:\n",
        "        return \"Moderate\"\n",
        "    else:\n",
        "        return \"Severe\"\n",
        "\n",
        "def analyze_and_display_mask_areas(prediction_result):\n",
        "    # Ensure that masks exist in the prediction result\n",
        "    if prediction_result.masks is None:\n",
        "        print(\"No segmentation masks available in the prediction result.\")\n",
        "        return\n",
        "\n",
        "    # Convert the masks tensor to a NumPy array\n",
        "    mask_data = prediction_result.masks.data.cpu().numpy()\n",
        "\n",
        "    # Calculate the total number of pixels (assuming all masks are from the same image dimensions)\n",
        "    img_height, img_width = mask_data.shape[1], mask_data.shape[2]\n",
        "    total_pixels = img_height * img_width\n",
        "\n",
        "    total_mask_area = 0  # Accumulator for all mask areas\n",
        "    pothole_areas = []   # List to store each pothole area\n",
        "\n",
        "    # Create subplots for each mask for visualization\n",
        "    num_masks = mask_data.shape[0]\n",
        "    fig, axes = plt.subplots(1, num_masks, figsize=(12, 8))\n",
        "    if num_masks == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    # Process each mask to compute area and draw contours\n",
        "    for idx, mask in enumerate(mask_data):\n",
        "        # Binarize the mask\n",
        "        binary = (mask > 0).astype(np.uint8) * 255\n",
        "        # Convert to BGR for drawing contours\n",
        "        mask_color = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)\n",
        "        # Find contours (if there are multiple contours, sum their areas)\n",
        "        contours, _ = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        mask_area = 0\n",
        "        for cnt in contours:\n",
        "            mask_area += cv2.contourArea(cnt)\n",
        "        pothole_areas.append(mask_area)\n",
        "        total_mask_area += mask_area\n",
        "\n",
        "        # Draw all contours in green on the mask image\n",
        "        cv2.drawContours(mask_color, contours, -1, (0, 255, 0), 3)\n",
        "        axes[idx].imshow(mask_color)\n",
        "        axes[idx].set_title(f'Pothole {idx+1}')\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print individual pothole areas\n",
        "    for i, area in enumerate(pothole_areas):\n",
        "        damage_pct = (area / total_pixels) * 100\n",
        "        print(f\"Pothole {i+1} Area: {area:.2f} pixels ({damage_pct:.2f}% of image)\")\n",
        "\n",
        "    # Print overall statistics\n",
        "    overall_damage_pct = (total_mask_area / total_pixels) * 100\n",
        "    overall_severity = classify_severity(overall_damage_pct)\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Total Pothole Area: {total_mask_area:.2f} pixels\")\n",
        "    print(f\"Total Image Area: {total_pixels} pixels\")\n",
        "    print(f\"Overall Road Damage: {overall_damage_pct:.2f}%\")\n",
        "    print(f\"Overall Damage Severity: {overall_severity}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTVwezNdtteo"
      },
      "outputs": [],
      "source": [
        "# Define the directory containing validation images\n",
        "testing_images_directory = os.path.join(dataset_dir, 'test', 'images')\n",
        "\n",
        "# Run inference and display results for the image at index 25; store the prediction result\n",
        "predicted_results = display_inference_and_masks(testing_images_directory, sample_idx=15, yolo_model=best_model, img_size=640, conf_thresh=0.5)\n",
        "\n",
        "# Analyze and display mask areas (with severity classification) using the first prediction result\n",
        "analyze_and_display_mask_areas(predicted_results[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YCf6xLdCXTcx"
      },
      "outputs": [],
      "source": [
        "def process_video_damage(video_input, video_output, yolo_model, frame_resize=640, confidence=0.25, smoothing_window=3):\n",
        "    # Annotation settings\n",
        "    text_font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    text_scale = 1\n",
        "    text_origin = (40, 80)\n",
        "    text_color = (255, 255, 255)   # White text\n",
        "    text_bg_color = (0, 0, 255)      # Red background for text\n",
        "\n",
        "    # Initialize a fixed-length deque to store recent damage percentages for smoothing\n",
        "    damage_history = deque(maxlen=smoothing_window)\n",
        "\n",
        "    # Open the input video stream\n",
        "    cap = cv2.VideoCapture(video_input)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Setup video writer with the XVID codec\n",
        "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    writer = cv2.VideoWriter(video_output, codec, 20.0, (width, height))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Run the YOLO model on the current frame\n",
        "        inference = yolo_model.predict(source=frame, imgsz=frame_resize, conf=confidence)\n",
        "        # Obtain the annotated frame\n",
        "        annotated_frame = inference[0].plot(boxes=True)\n",
        "\n",
        "        # Initialize damage area for the current frame\n",
        "        current_damage_area = 0.0\n",
        "        total_pixels = frame.shape[0] * frame.shape[1]\n",
        "        mask_details = []  # List to store individual mask details\n",
        "\n",
        "        # If segmentation masks exist, compute the area for each detected mask\n",
        "        if inference[0].masks is not None:\n",
        "            mask_data = inference[0].masks.data.cpu().numpy()\n",
        "            for i, mask in enumerate(mask_data):\n",
        "                # Convert mask to a binary image\n",
        "                binary_img = (mask > 0).astype(np.uint8) * 255\n",
        "                # Find contours; sum the area of all contours in this mask\n",
        "                cnts, _ = cv2.findContours(binary_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                mask_area = 0.0\n",
        "                for cnt in cnts:\n",
        "                    mask_area += cv2.contourArea(cnt)\n",
        "                current_damage_area += mask_area\n",
        "                mask_pct = (mask_area / total_pixels) * 100\n",
        "                mask_details.append((i+1, mask_area, mask_pct))\n",
        "\n",
        "        # Compute the damage percentage for the current frame\n",
        "        current_damage = (current_damage_area / total_pixels) * 1000\n",
        "\n",
        "        # Append current frame's damage percentage to the smoothing window and compute the average\n",
        "        damage_history.append(current_damage)\n",
        "        avg_damage = sum(damage_history) / len(damage_history)\n",
        "\n",
        "        # Determine overall severity based on the averaged damage percentage\n",
        "        severity_label = classify_severity(avg_damage)\n",
        "\n",
        "        # Print per-frame detailed mask information\n",
        "        for idx, area, pct in mask_details:\n",
        "            print(f\"Pothole {idx} Area: {area:.2f} pixels ({pct:.2f}% of image)\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Total Pothole Area: {current_damage_area:.2f} pixels\")\n",
        "        print(f\"Total Image Area: {total_pixels} pixels\")\n",
        "        print(f\"Overall Road Damage: {current_damage:.2f}%\")\n",
        "        print(f\"Overall Damage Severity: {severity_label}\")\n",
        "        print()\n",
        "\n",
        "        # Draw a background line for the annotation text\n",
        "        cv2.line(annotated_frame, (text_origin[0], text_origin[1] - 10),\n",
        "                 (text_origin[0] + 350, text_origin[1] - 10), text_bg_color, 40)\n",
        "        # Overlay the road damage percentage (using averaged value) on the frame\n",
        "        cv2.putText(annotated_frame, f'Road Damage: {avg_damage:.2f}%', text_origin,\n",
        "                    text_font, text_scale, text_color, 2, cv2.LINE_AA)\n",
        "        # Overlay the overall damage severity on the frame\n",
        "        severity_origin = (text_origin[0], text_origin[1] + 40)\n",
        "        cv2.putText(annotated_frame, f'Damage Severity: {severity_label}', severity_origin,\n",
        "                    text_font, text_scale, text_color, 2, cv2.LINE_AA)\n",
        "\n",
        "        # Write the annotated frame to the output video file\n",
        "        writer.write(annotated_frame)\n",
        "\n",
        "    # Release video capture and writer objects\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "\n",
        "# Example usage:\n",
        "video_in_path = '/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/sample_video.mp4'\n",
        "video_out_path = '/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/road_damage_assessment.avi'\n",
        "process_video_damage(video_in_path, video_out_path, best_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS5Ti5rmhT41"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(os.path.exists('/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/road_damage_assessment.avi'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "uN5Wef4SW7-4"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "export LC_ALL=en_US.UTF-8\n",
        "export LANG=en_US.UTF-8\n",
        "ffmpeg -i '/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/road_damage_assessment.avi' \\\n",
        "-c:v libx264 -preset fast -crf 22 -c:a aac -strict experimental \\\n",
        "'/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/road_damage_assessment_.mp4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eW1iztlcgrCP"
      },
      "outputs": [],
      "source": [
        "# Embed and display the video in the notebook\n",
        "\n",
        "Video_Visual = Video('/content/drive/MyDrive/Machine_Vision/New_Pothole_Dataset/road_damage_assessment_.mp4', embed=True, width=600, height=400)\n",
        "\n",
        "Video_Visual"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}